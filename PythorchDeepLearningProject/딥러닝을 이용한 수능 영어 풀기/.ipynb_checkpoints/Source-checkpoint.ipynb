{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478749c7",
   "metadata": {},
   "source": [
    "### [모듈 불러오기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4f0a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\choic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import BucketIterator\n",
    "from torchtext.data import Iterator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1098e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2020\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "DATA_PATH = \"data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff9232d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a2055",
   "metadata": {},
   "source": [
    "### [모델 클래스 정의하기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c845d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embed_layer = nn.Embedding(\n",
    "            # 생성할 Embedding Layer의 크기를 정해줌, 보통은 단어장의 크기\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim,\n",
    "            # 자연어 처리에서 배치별로 문장의 크기를 맞추기 위해서 짧은 문장에 Padding을 붙여서 길이를 맞춤\n",
    "            # 그런데 이 Padding은 특별한 의미를 갖고 있지 않음\n",
    "            # 학습에서 제외하기 위해 Padding이 단어장에서 어떤 숫자를 갖고 있는지 알려줌으로써 학습되지 않게 함.\n",
    "            padding_idx=pad_idx\n",
    "        )\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=0.5\n",
    "        )\n",
    "        self.last_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            # 마지막 Output 크기를 1로 줌 (맞는지 아닌지 점수가 가장 낮은 문장이 문법적으로 맞지 않다고 판단)\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 이 모델은 숫자로 이루어진 토큰을 Input으로 받는다고 가정\n",
    "        # 그렇기에 우선 들어온 Input 값을 Embedding 값으로 변환시켜 주어야 함\n",
    "        embed_x = self.embed_layer(x)\n",
    "        # LSTM은 Output, (Hidden State, Cell State)를 반환 함, 이 중 State 값들은 사용하지 않으므로 반환 받지 않음\n",
    "        output, (_, _) = self.lstm_layer(embed_x)\n",
    "        # LSTM의 Output은 (배치 크기, 문장 길이, Output Size)라는 Size를 갖고 있음. 가장 마지막 단어의 결과 값만 사용\n",
    "        last_output = output[:, -1, :]\n",
    "        # 문장의 마지막 단어의 Output을 Fully Connected Layer에 통과시켜 확률값을 계산\n",
    "        last_output = self.last_layer(last_output)\n",
    "        return last_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f808e",
   "metadata": {},
   "source": [
    "### [모델 파이프라인 정의]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad2ee09",
   "metadata": {},
   "source": [
    "## >데이터셋 불러오기<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e3960",
   "metadata": {},
   "source": [
    "**파일에서 필요한 Field 선언하기**  \n",
    "1 TEXT = Field(...)  \n",
    "2 LABEL = Field(...)  \n",
    "**데이터 불러오기**  \n",
    "3 dataset = TabularDataset  \n",
    "**불러온 데이터로 단어장 만들기**  \n",
    "4 TEXT.build_vocab(dataset)  \n",
    "**Data Loader 만들기**  \n",
    "5 data_loadet = BucketIterator(dataset, ..)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "072b4d04",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)  \n",
    "문장은 TEXT, 정답은 LABEL로 각각의 Field를 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8124bb3",
   "metadata": {},
   "source": [
    "### [문장 필드 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb84a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choic\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "TEXT = Field(\n",
    "    sequential=True, # 1\n",
    "    use_vocab=True, # 2\n",
    "    tokenize=word_tokenize, # 3\n",
    "    lower=True, # 4\n",
    "    batch_first=True # 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b999c7e",
   "metadata": {},
   "source": [
    "1. TEXT는 문장이 들어오는 Field. Sequential=True로 설정해서 이 필드에는 문장이 들어온다는 것을 알려줌\n",
    "2. 단어를 숫자로 변환시켜주는 단어장을 만들기 위해 이 필드를 이용함\n",
    "3. 불러온 문장을 토크나이징 할 함수를 입력. nltk의 word_tokenize를 이용 할 것임. word_tokenize는 영어로 이루어진 문장을 토큰화시킬 때 가장 기본적으로 사용됨.\n",
    "4. 대소문자를 구분할지 말지를 설정하는 부분. 따로 대명사를 처리하지 않을 것이기에 모두 소문자로 처리\n",
    "5. 자연어를 처리하는 모듈별로 지원하는 데이터의 형태가 다름. 크게 다음 두가지 형태가 있음.\n",
    "- (배치, 문장)\n",
    "- (문장, 배치)  \n",
    "이 중 첫 번째의 방식이 필요하기에 True를 줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7f7d32",
   "metadata": {},
   "source": [
    "### [정답 필드 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d7e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = Field(\n",
    "    sequential=False, # 1\n",
    "    use_vocab=False, # 2\n",
    "    batch_first=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360d49e",
   "metadata": {},
   "source": [
    "1. 앞에서는 문장이 들어오기 때문에 True를 주었지만 이 열은 정답이 있는 열이기에 False를 줌\n",
    "2. 또한 이 Field에서는 따로 단어장을 생성하지 않기에 False를 줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada077b",
   "metadata": {},
   "source": [
    "### [데이터 불러오기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dcc77ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choic\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "C:\\Users\\choic\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "sat_train_data, sat_valid_data, sat_test_data = \\\n",
    "    TabularDataset.splits(\n",
    "    path='data/processed', # 1\n",
    "    train='sat_train.tsv', # 2\n",
    "    validation='sat_valid.tsv',\n",
    "    test = 'sat_test.tsv',\n",
    "    format = 'tsv', # 3\n",
    "    fields = [('text', TEXT), ('label', LABEL)], # 4\n",
    "    skip_header = 1, # 5\n",
    ")\n",
    "TEXT.build_vocab(sat_train_data, min_freq=2) # 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c30135",
   "metadata": {},
   "source": [
    "1. 데이터가 들어 있는 폴더의 경로를 입력\n",
    "2. 각각 Train, Validation, Test의 파일명을 입력\n",
    "3. 데이터의 파일 포맷 형태를 줍니다. 사용할 데이터는 Tap separated value의 데이터이기에 tsv를 입력\n",
    "4. 앞에서 정의한 Field를 입력해주는 부분. 입력할 때 실제 데이터의 컬럼 순서로 입력해주어야함. 그리고 Field의 이름과 Field를 묶음. 예를 들어 (\"text\", TEXT)라면 이 데이터는 첫 번째 컬럼에 문장이 있고 그 컬럼명을 text로 하겠다는 뜻\n",
    "5. 데이터의 첫 번째 열에는 원래의 컬럼명이 들어 있음. 데이터로 사용되지 않기 때문에 따로 불러오지 않도록 해야함. 그렇기에 1을 주어서 첫 번째 열을 생략하도록 함.\n",
    "6. 마지막으로 불러온 데이터 중 훈련 데이터를 이용해 TEXT의 단어장을 생성함\n",
    "\n",
    "불러온 데이터로 Data Loader를 만들어야 하는데 일반적인 Data Loader은  \n",
    "랜덤하게 추출 -> 각 문장을 정해진 길이에 맞추기 -> Tensor로 변환  \n",
    "\n",
    "정해진 길이에 맞추기 : torchtext.BucketIterator 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249925d2",
   "metadata": {},
   "source": [
    "### [Data Loader 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93023997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choic\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "sat_train_iterator, sat_valid_iterator, sat_test_iterator = \\\n",
    "    BucketIterator.splits(\n",
    "        (sat_train_data, sat_valid_data, sat_test_data),\n",
    "        batch_size=8,\n",
    "        device=None,\n",
    "        sort=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382df1cd",
   "metadata": {},
   "source": [
    "1. 앞에서 불러온 데이터들을 묶어서 입력해줌\n",
    "2. Data Loader에서 각 배치별 크기를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27682175",
   "metadata": {},
   "source": [
    "## >학습<  \n",
    "  \n",
    "1. Data Loader에서 배치 불러오기\n",
    "2. 배치를 모델에 넣어서 데이터 형태 맞추기\n",
    "3. 배치를 모델에 넣어서 예측값 얻기\n",
    "4. 정답과 예측값을 비교해서 Loss 계산하기\n",
    "5. Loss를 이용해 모델 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a00283",
   "metadata": {},
   "source": [
    "### [모델 학습 함수 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f374bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader: # 1\n",
    "        optimizer.zero_grad()\n",
    "        text = batch.text\n",
    "        if text.shape[0] > 1:\n",
    "            label = batch.label.type(torch.FloatTensor) # 3\n",
    "            text = text.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(text).flatten() # 4\n",
    "            loss = criterion(output, label) # 5\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fb8a3e",
   "metadata": {},
   "source": [
    "train\n",
    "1. 입력 받은 Data Loader를 호출해 Batch를 부르는 코드\n",
    "2. Batch는 두 개의 Attribute를 갖고 있음. 앞서 데이터를 불러올 때 준 fields=[(\"text\", TEXT), (\"label\", LABEL)]에서 앞의 단어들. 여기서 text는 batch의 문장, label은 Batch의 정답을 갖고 있음\n",
    "3. 문장과 정답을 불러와서 필요한 데이터 형태로 변환\n",
    "4. 모델에 문장을 넣어서 결과를 출력\n",
    "5. 출력된 겨로가와 정답을 비교해서 Loss를 구함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453165a",
   "metadata": {},
   "source": [
    "### [모델 평가 함수 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a088124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valid_loader, optimizer, criterion, device):\n",
    "    model.eval() # 1\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad(): # 2\n",
    "        for _, batch in enumerate(valid_loader):\n",
    "            text = batch.text\n",
    "            label = batch.label.type(torch.FloatTensor)\n",
    "            text = text.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(text).flatten()\n",
    "            loss = criterion(output, label)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce20a61",
   "metadata": {},
   "source": [
    "1. Dropout과 같이 훈련과 평가의 동작이 다른 모듈들은 각 목적에 맞게 변화를 주어야 함. 여기서는 평가를 하기 위해 model.eval()를 먼저 선언\n",
    "2. torch에서는 기본적으로 Forward를 할 때 자동으로 Gradient를 계산. 하지만 평가를 진행할 때는 Gradient를 계산할 필요가 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a1300",
   "metadata": {},
   "source": [
    "### [HyperParameter 선언]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26ae085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "N_EPOCHS = 20\n",
    "\n",
    "lstm_classifier = LSTMClassifier(\n",
    "    num_embeddings=len(TEXT.vocab),\n",
    "    embedding_dim=100,\n",
    "    hidden_size=200,\n",
    "    num_layers=4,\n",
    "    pad_idx=PAD_IDX,\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "_ = lstm_classifier.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_classifier.parameters())\n",
    "bce_loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd989a9a",
   "metadata": {},
   "source": [
    "### [모델 학습]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41077b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choic\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.53348\n",
      "\t Val. Loss: 0.75698\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.52014\n",
      "\t Val. Loss: 0.56375\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.47775\n",
      "\t Val. Loss: 0.55127\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.44323\n",
      "\t Val. Loss: 0.54704\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.42197\n",
      "\t Val. Loss: 0.55199\n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.41107\n",
      "\t Val. Loss: 0.56374\n",
      "Epoch: 07\n",
      "\tTrain Loss: 0.42162\n",
      "\t Val. Loss: 0.56400\n",
      "Epoch: 08\n",
      "\tTrain Loss: 0.43142\n",
      "\t Val. Loss: 0.53967\n",
      "Epoch: 09\n",
      "\tTrain Loss: 0.46181\n",
      "\t Val. Loss: 0.54005\n",
      "Epoch: 10\n",
      "\tTrain Loss: 0.43902\n",
      "\t Val. Loss: 0.54140\n",
      "Epoch: 11\n",
      "\tTrain Loss: 0.45546\n",
      "\t Val. Loss: 0.54697\n",
      "Epoch: 12\n",
      "\tTrain Loss: 0.45420\n",
      "\t Val. Loss: 0.54316\n",
      "Epoch: 13\n",
      "\tTrain Loss: 0.41215\n",
      "\t Val. Loss: 0.56632\n",
      "Epoch: 14\n",
      "\tTrain Loss: 0.41748\n",
      "\t Val. Loss: 0.60505\n",
      "Epoch: 15\n",
      "\tTrain Loss: 0.44161\n",
      "\t Val. Loss: 0.57962\n",
      "Epoch: 16\n",
      "\tTrain Loss: 0.43434\n",
      "\t Val. Loss: 0.55206\n",
      "Epoch: 17\n",
      "\tTrain Loss: 0.46020\n",
      "\t Val. Loss: 0.54843\n",
      "Epoch: 18\n",
      "\tTrain Loss: 0.42365\n",
      "\t Val. Loss: 0.56666\n",
      "Epoch: 19\n",
      "\tTrain Loss: 0.43033\n",
      "\t Val. Loss: 0.54686\n",
      "Epoch: 20\n",
      "\tTrain Loss: 0.41675\n",
      "\t Val. Loss: 0.56571\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(\n",
    "        lstm_classifier,\n",
    "        sat_train_iterator,\n",
    "        optimizer,\n",
    "        bce_loss_fn,\n",
    "        device = device\n",
    "    )\n",
    "    valid_loss = evaluate(\n",
    "        lstm_classifier,\n",
    "        sat_valid_iterator,\n",
    "        optimizer,\n",
    "        criterion = bce_loss_fn,\n",
    "        device = device\n",
    "    )\n",
    "    print(f\"Epoch: {epoch+1:02}\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.5f}\")\n",
    "    print(f\"\\t Val. Loss: {valid_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be914d0",
   "metadata": {},
   "source": [
    "### [모델 저장]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41bd344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"baseline_model.dill\", \"wb\") as f:\n",
    "    model = {\n",
    "        \"TEXT\": TEXT,\n",
    "        \"LABEL\": LABEL,\n",
    "        \"classifier\": lstm_classifier\n",
    "    }\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9258c7f",
   "metadata": {},
   "source": [
    "## > Test <  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5efb1a2",
   "metadata": {},
   "source": [
    "모델이 얼마나 잘 맞히는지 판단하기 위해 **Area Under Receiver Operating Characteristic(AUROC)**를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1735f6",
   "metadata": {},
   "source": [
    "### [AUROC]  \n",
    "\n",
    "Output의 크기가 2라면 모델의 성능지표로써 정확도(Accuracy)를 사용하면 됨. 하지만 Output 크기가 1일 때는 정확도가 Threshold에 의해서 변하게 됨.  \n",
    "예를 들어 아래와 같은 예측값과 정답이 있다고 가정해 보겠음"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ded5e147",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b638e",
   "metadata": {},
   "source": [
    "확률이 0.5가 넘을 경우 문법적으로 맞는 문장, 넘지 않을 경우 문법적으로 틀린 문장이라고 가정. 그러면 이 모델의 예측값은 아래와 같이 바뀌게 됨"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2ceab451",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4978178",
   "metadata": {},
   "source": [
    "정확도가 66%인 모델이 됨. 그런데 확률을 0.5 대신 0.52로 변경하면 정확도가 100%인 모델이 됨.  \n",
    "이처럼 Threshold에 의해 정확도가 변하기 때문에 정확도를 신뢰하기 어려움. Threshold에 의해 변하는 값을 보완하기 위한 평가 척도가 AUROC임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5029a096",
   "metadata": {},
   "source": [
    "### [테스트 함수 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "590d2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_real = []\n",
    "        y_pred = []\n",
    "        \n",
    "        for batch in test_loader:\n",
    "            text = batch.text\n",
    "            label = batch.label.type(torch.FloatTensor)\n",
    "            text = text.to(device)\n",
    "            \n",
    "            output = model(text).flatten().cpu()\n",
    "            \n",
    "            y_real += [label] # 1\n",
    "            y_pred += [output]\n",
    "            \n",
    "        y_real = torch.cat(y_real) # 2\n",
    "        y_pred = torch.cat(y_pred)\n",
    "        \n",
    "    fpr, tpr, _ = roc_curve(y_real, y_pred) # 3\n",
    "    auroc = auc(fpr, tpr)\n",
    "    \n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ca861",
   "metadata": {},
   "source": [
    "1. Test 결과를 보기 위해 각 Batch의 예측값을 List에 모음\n",
    "2. 모인 예측값들을 합쳐줌\n",
    "3. 예측값과 정답을 이용해 AUROC를 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf51e9f",
   "metadata": {},
   "source": [
    "### [모델 성능 확인]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68fa4174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAT Dataset Test AUROC: 0.57692\n"
     ]
    }
   ],
   "source": [
    "_ = lstm_classifier.cpu()\n",
    "test_auroc = test(\n",
    "    lstm_classifier, # 1\n",
    "    sat_test_iterator, # 2\n",
    "    \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"SAT Dataset Test AUROC: {test_auroc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505bd80f",
   "metadata": {},
   "source": [
    "1. 학습이 끝난 모델을 입력.\n",
    "2. 수능 Test 데이터를 입력해 결과를 확인."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a3ad9",
   "metadata": {},
   "source": [
    "일반적으로 AUROC의 기준값을 0.5로 보는데, 이 0.5라는 숫자는 동전을 던지는 확률과 같음. 그런데 이 모델은 0.57로 동전을 던지는 것보다 약간 더 좋은 상태임. 성능이 낮은 이유를 생각해보면 크게 두 가지\n",
    "  \n",
    "1. 데이터가 부족함\n",
    "2. 모델의 성능이 문제를 풀기에 부족함  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc2542c",
   "metadata": {},
   "source": [
    "# 성능 높이기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdbeda3",
   "metadata": {},
   "source": [
    "## > 추가 데이터 이용 <"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b024b",
   "metadata": {},
   "source": [
    "부족한 데이터 모음 -> 수능 문제는 추가적으로 구하기 어려움  \n",
    "그래서 추가적인 데이터를 구하기 ㄷ위해 공개된 데이터 셋을 활용  \n",
    "Corpus of Linguistically Acceptable(CoLA) 데이터셋을 이용.  \n",
    "CoLa데이터셋: 문장이 주어지면 그 문장이 문법적으로 받아들일 수 있는지를 풀고자 하는 문제들  \n",
    "\n",
    "Train 데이터에 추가해서 학습 시키면 될 것 같은데?  \n",
    "데이터 크기 차이 때문에 무리, CoLA가 1:10 비율로 훨신 더 많음 -> 편향된 결과!  \n",
    "\n",
    "따라서 이 데이터는 Pre-Trained Model에 사용하고자 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8f5bbf",
   "metadata": {},
   "source": [
    "### [사전 학습 데이터 불러오기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6243589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choic\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "sat_train_data, sat_valid_data, sat_test_data = \\\n",
    "    TabularDataset.splits(\n",
    "        path=\"data/processed\",\n",
    "        train=\"sat_train.tsv\",\n",
    "        validation=\"sat_valid.tsv\",\n",
    "        test=\"sat_test.tsv\",\n",
    "        format=\"tsv\",\n",
    "        fields=[(\"text\", TEXT), (\"label\", LABEL)],\n",
    "        skip_header=1,\n",
    "    )\n",
    "sat_train_iterator, sat_valid_iterator, sat_test_iterator = \\\n",
    "    BucketIterator.splits(\n",
    "        (sat_train_data, sat_valid_data, sat_test_data),\n",
    "        batch_size=8,\n",
    "        device=None,\n",
    "        sort=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91b1b2e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25348/3244687233.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tsv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mskip_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcola_train_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\dataset.py\u001b[0m in \u001b[0;36msplits\u001b[1;34m(cls, path, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         train_data = None if train is None else cls(\n\u001b[1;32m---> 78\u001b[1;33m             os.path.join(path, train), **kwargs)\n\u001b[0m\u001b[0;32m     79\u001b[0m         val_data = None if validation is None else cls(\n\u001b[0;32m     80\u001b[0m             os.path.join(path, validation), **kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, format, fields, skip_header, csv_reader_params, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[0mexamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmake_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[0mexamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmake_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\example.py\u001b[0m in \u001b[0;36mfromCSV\u001b[1;34m(cls, data, fields, field_to_index)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfield_to_index\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\example.py\u001b[0m in \u001b[0;36mfromlist\u001b[1;34m(cls, data, fields)\u001b[0m\n\u001b[0;32m     87\u001b[0m                         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                     \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\field.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    210\u001b[0m         `preprocessing` Pipeline.\"\"\"\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m     return [\n\u001b[0;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m    106\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1274\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m         \"\"\"\n\u001b[1;32m-> 1276\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1330\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m         \"\"\"\n\u001b[1;32m-> 1332\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_match_potential_end_contexts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1330\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m         \"\"\"\n\u001b[1;32m-> 1332\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_match_potential_end_contexts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m             \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \"\"\"\n\u001b[0;32m   1420\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1421\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msentence1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1422\u001b[0m             \u001b[0msentence1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msentence2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[0miterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1393\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1395\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_match_potential_end_contexts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1397\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_break\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_match_potential_end_contexts\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1380\u001b[0m             \u001b[0msplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxsplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m             \u001b[0mbefore_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m             \u001b[0mbefore_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1383\u001b[0m             \u001b[0mmatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "TEXT = Field(\n",
    "    sequential=True,\n",
    "    use_vocab=True,\n",
    "    tokenize=word_tokenize,\n",
    "    lower=True,\n",
    "    batch_first=True,\n",
    ")\n",
    "LABEL = Field(\n",
    "    sequential=False,\n",
    "    use_vocab=False,\n",
    "    batch_first=True,\n",
    ")\n",
    "cola_train_data, cola_valid_data, cola_test_data = \\\n",
    "    TabularDataset.splits(\n",
    "        path=DATA_PATH,\n",
    "        train=\"cola_train.tsv\",\n",
    "        validation=\"cola_valid.tsv\",\n",
    "        test=\"cola_test.tsv\",\n",
    "        format=\"tsv\",\n",
    "        fields=[(\"text\", TEXT), (\"label\", LABEL)],\n",
    "        skip_header=1,\n",
    ")\n",
    "TEXT.build_vocab(cola_train_data, min_freq=2)\n",
    "cola_train_iterator, cola_valid_iterator, cola_test_iterator = \\\n",
    "    BucketIterator.splits(\n",
    "        (cola_train_data, cola_valid_data, cola_test_data),\n",
    "        batch_size=32,\n",
    "        device=None,\n",
    "        sort=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d67a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythorchDeepLearningProject",
   "language": "python",
   "name": "book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
