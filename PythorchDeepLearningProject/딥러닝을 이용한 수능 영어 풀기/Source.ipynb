{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478749c7",
   "metadata": {},
   "source": [
    "### [모듈 불러오기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f4f0a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\choic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import BucketIterator\n",
    "from torchtext.data import Iterator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1098e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2020\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "DATA_PATH = \"data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff9232d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a2055",
   "metadata": {},
   "source": [
    "### [모델 클래스 정의하기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c845d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_embeddings, embedding_dim, hidden_size, num_layers, pad_idx\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_layer = nn.Embedding(\n",
    "        # 생성할 Embedding Layer의 크기를 정해줌, 보통은 단어장의 크기\n",
    "        num_embeddings=num_embeddings,\n",
    "        embedding_dim=embedding_dim,\n",
    "        # 자연어 처리에서 배치별로 문장의 크기를 맞추기 위해서 짧은 문장에 Padding을 붙여서 길이를 맞춤\n",
    "        # 그런데 이 Padding은 특별한 의미를 갖고 있지 않음\n",
    "        # 학습에서 제외하기 위해 Padding이 단어장에서 어떤 숫자를 갖고 있는지 알려줌으로써 학습되지 않게 함.\n",
    "        padding_idx=pad_idx\n",
    "        )\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=0.5\n",
    "        )\n",
    "        self.last_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            # 마지막 Output 크기를 1로 줌 (맞는지 아닌지 점수가 가장 낮은 문장이 문법적으로 맞지 않다고 판단)\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f808e",
   "metadata": {},
   "source": [
    "### [모델 파이프라인 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5be056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    # 이 모델은 숫자로 이루어진 토큰을 Input으로 받는다고 가정\n",
    "    # 그렇기에 우선 들어온 Input 값을 Embedding 값으로 변환시켜 주어야 함\n",
    "    embed_x = self.embed_layer(x)\n",
    "    # LSTM은 Output, (Hidden State, Cell State)를 반환 함, 이 중 State 값들은 사용하지 않으므로 반환 받지 않음\n",
    "    output, (_, _) = self.lstm_layer(embed_x)\n",
    "    # LSTM의 Output은 (배치 크기, 문장 길이, Output Size)라는 Size를 갖고 있음. 가장 마지막 단어의 결과 값만 사용\n",
    "    last_output = output[:, -1, :]\n",
    "    # 문장의 마지막 단어의 Output을 Fully Connected Layer에 통과시켜 확률값을 계산\n",
    "    last_ouput = self.last_layer(last_output)\n",
    "    return last_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad2ee09",
   "metadata": {},
   "source": [
    "## >데이터셋 불러오기<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e3960",
   "metadata": {},
   "source": [
    "**파일에서 필요한 Field 선언하기**  \n",
    "1 TEXT = Field(...)  \n",
    "2 LABEL = Field(...)  \n",
    "**데이터 불러오기**  \n",
    "3 dataset = TabularDataset  \n",
    "**불러온 데이터로 단어장 만들기**  \n",
    "4 TEXT.build_vocab(dataset)  \n",
    "**Data Loader 만들기**  \n",
    "5 data_loadet = BucketIterator(dataset, ..)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "072b4d04",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)  \n",
    "문장은 TEXT, 정답은 LABEL로 각각의 Field를 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8124bb3",
   "metadata": {},
   "source": [
    "### [문장 필드 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb84a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choic\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "TEXT = Field(\n",
    "    sequential=True, # 1\n",
    "    use_vocab=True, # 2\n",
    "    tokenize=word_tokenize, # 3\n",
    "    lower=True, # 4\n",
    "    batch_first=True # 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b999c7e",
   "metadata": {},
   "source": [
    "1. TEXT는 문장이 들어오는 Field. Sequential=True로 설정해서 이 필드에는 문장이 들어온다는 것을 알려줌\n",
    "2. 단어를 숫자로 변환시켜주는 단어장을 만들기 위해 이 필드를 이용함\n",
    "3. 불러온 문장을 토크나이징 할 함수를 입력. nltk의 word_tokenize를 이용 할 것임. word_tokenize는 영어로 이루어진 문장을 토큰화시킬 때 가장 기본적으로 사용됨.\n",
    "4. 대소문자를 구분할지 말지를 설정하는 부분. 따로 대명사를 처리하지 않을 것이기에 모두 소문자로 처리\n",
    "5. 자연어를 처리하는 모듈별로 지원하는 데이터의 형태가 다름. 크게 다음 두가지 형태가 있음.\n",
    "- (배치, 문장)\n",
    "- (문장, 배치)  \n",
    "이 중 첫 번째의 방식이 필요하기에 True를 줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7f7d32",
   "metadata": {},
   "source": [
    "### [정답 필드 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d7e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = Field(\n",
    "    sequential=False, # 1\n",
    "    use_vocab=False, # 2\n",
    "    batch_first=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360d49e",
   "metadata": {},
   "source": [
    "1. 앞에서는 문장이 들어오기 때문에 True를 주었지만 이 열은 정답이 있는 열이기에 False를 줌\n",
    "2. 또한 이 Field에서는 따로 단어장을 생성하지 않기에 False를 줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada077b",
   "metadata": {},
   "source": [
    "### [데이터 불러오기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dcc77ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choic\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "C:\\Users\\choic\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "sat_train_data, sat_valid_data, sat_test_data = \\\n",
    "    TabularDataset.splits(\n",
    "    path='data/processed', # 1\n",
    "    train='sat_train.tsv', # 2\n",
    "    validation='sat_valid.tsv',\n",
    "    test = 'sat_test.tsv',\n",
    "    format = 'tsv', # 3\n",
    "    fields = [('text', TEXT), ('label', LABEL)], # 4\n",
    "    skip_header = 1, # 5\n",
    ")\n",
    "TEXT.build_vocab(sat_train_data, min_freq=2) # 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c30135",
   "metadata": {},
   "source": [
    "1. 데이터가 들어 있는 폴더의 경로를 입력\n",
    "2. 각각 Train, Validation, Test의 파일명을 입력\n",
    "3. 데이터의 파일 포맷 형태를 줍니다. 사용할 데이터는 Tap separated value의 데이터이기에 tsv를 입력\n",
    "4. 앞에서 정의한 Field를 입력해주는 부분. 입력할 때 실제 데이터의 컬럼 순서로 입력해주어야함. 그리고 Field의 이름과 Field를 묶음. 예를 들어 (\"text\", TEXT)라면 이 데이터는 첫 번째 컬럼에 문장이 있고 그 컬럼명을 text로 하겠다는 뜻\n",
    "5. 데이터의 첫 번째 열에는 원래의 컬럼명이 들어 있음. 데이터로 사용되지 않기 때문에 따로 불러오지 않도록 해야함. 그렇기에 1을 주어서 첫 번째 열을 생략하도록 함.\n",
    "6. 마지막으로 불러온 데이터 중 훈련 데이터를 이용해 TEXT의 단어장을 생성함\n",
    "\n",
    "불러온 데이터로 Data Loader를 만들어야 하는데 일반적인 Data Loader은  \n",
    "랜덤하게 추출 -> 각 문장을 정해진 길이에 맞추기 -> Tensor로 변환  \n",
    "\n",
    "정해진 길이에 맞추기 : torchtext.BucketIterator 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249925d2",
   "metadata": {},
   "source": [
    "### [Data Loader 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93023997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choic\\anaconda3\\envs\\book\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "sat_train_iterator, sat_valid_iterator, sat_test_iterator = BucketIterator.splits(\n",
    "    (sat_train_data, sat_valid_data, sat_test_data),\n",
    "    batch_size=8,\n",
    "    device=None,\n",
    "    sort=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382df1cd",
   "metadata": {},
   "source": [
    "1. 앞에서 불러온 데이터들을 묶어서 입력해줌\n",
    "2. Data Loader에서 각 배치별 크기를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27682175",
   "metadata": {},
   "source": [
    "## >학습<  \n",
    "  \n",
    "1. Data Loader에서 배치 불러오기\n",
    "2. 배치를 모델에 넣어서 데이터 형태 맞추기\n",
    "3. 배치를 모델에 넣어서 예측값 얻기\n",
    "4. 정답과 예측값을 비교해서 Loss 계산하기\n",
    "5. Loss를 이용해 모델 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a00283",
   "metadata": {},
   "source": [
    "### [모델 학습 함수 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f374bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, iterator: Iterator, optimizer: torch.optim.Optimizer, criterion: nn.Module, device: str):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for _, batch in enumerate(iterator): # 1\n",
    "        optimizer.zero_grad()\n",
    "        text = batch.text # 2\n",
    "        if text.shape[0] > 1:\n",
    "            label = batch.label.type(torch.FloatTensor) # 3\n",
    "            text = text.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(text).flatten() # 4\n",
    "            loss = criterion(output, label) # 5\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fb8a3e",
   "metadata": {},
   "source": [
    "1. 입력 받은 Data Loader를 호출해 Batch를 부르는 코드\n",
    "2. Batch는 두 개의 Attribute를 갖고 있음. 앞서 데이터를 불러올 때 준 fields=[(\"text\", TEXT), (\"label\", LABEL)]에서 앞의 단어들. 여기서 text는 batch의 문장, label은 Batch의 정답을 갖고 있음\n",
    "3. 문장과 정답을 불러와서 필요한 데이터 형태로 변환\n",
    "4. 모델에 문장을 넣어서 결과를 출력\n",
    "5. 출력된 겨로가와 정답을 비교해서 Loss를 구함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453165a",
   "metadata": {},
   "source": [
    "### [모델 평가 함수 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a088124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, iterator: Iterator, criterion: nn.Module, device: str):\n",
    "    model.eval() # 1\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad(): # 2\n",
    "        for _, batch in enumerate(iterator):\n",
    "            text = batch.text\n",
    "            label = batch.label.type(torch.FloatTensor)\n",
    "            text = text.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(text).flatten()\n",
    "            loss = criterion(output, label)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce20a61",
   "metadata": {},
   "source": [
    "1. Dropout과 같이 훈련과 평가의 동작이 다른 모듈들은 각 목적에 맞게 변화를 주어야 함. 여기서는 평가를 하기 위해 model.eval()를 먼저 선언\n",
    "2. torch에서는 기본적으로 Forward를 할 때 자동으로 Gradient를 계산. 하지만 평가를 진행할 때는 Gradient를 계산할 필요가 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8e4b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(model: nn.Module, iterator: Iterator, device: str):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_real = []\n",
    "        y_pred = []\n",
    "        for batch in iterator:\n",
    "            text = batch.text\n",
    "            label = batch.label.type(torch.FloatTensor)\n",
    "            text = text.to(device)\n",
    "            output = model(text).flatten().cpu()\n",
    "            y_real += [label]\n",
    "            y_pred += [output]\n",
    "        y_real = torch.cat(y_real)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_real, y_pred)\n",
    "    auroc = auc(fpr, tpr)\n",
    "\n",
    "    return auroc\n",
    "\n",
    "\n",
    "def epoch_time(start_time: int, end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a1300",
   "metadata": {},
   "source": [
    "### [HyperParameter 선언]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26ae085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "N_EPOCHS = 20\n",
    "\n",
    "lstm_classifier = LSTMClassifier(\n",
    "    num_embeddings=len(TEXT.vocab),\n",
    "    embedding_dim=100,\n",
    "    hidden_size=200,\n",
    "    num_layers=4,\n",
    "    pad_idx=PAD_IDX,\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "_ = lstm_classifier.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_classifier.parameters())\n",
    "bce_loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd989a9a",
   "metadata": {},
   "source": [
    "### [모델 학습]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41077b8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11712/1939790937.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_classifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msat_train_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbce_loss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_classifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msat_valid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbce_loss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11712/1180825097.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\book\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \"\"\"\n\u001b[1;32m--> 175\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(lstm_classifier, sat_train_iterator, optimizer, bce_loss_fn, device)\n",
    "    valid_loss = evaluate(lstm_classifier, sat_valid_iterator, bce_loss_fn, device)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.5f}\")\n",
    "    print(f\"\\t Val. Loss: {valid_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a70f397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythorchDeepLearningProject",
   "language": "python",
   "name": "book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
